{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GYvVzQ7eZSo",
        "outputId": "840ebb55-7ea2-4da3-e87a-e9d9798a4216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        " from google.colab import drive\n",
        " drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/My Drive/ADNI/ADNI_AD_NC_2D.zip' -d 'sample_data/data/'"
      ],
      "metadata": {
        "id": "EZTqMS8Ci5Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader,SubsetRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "x8xCaa3njV3O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'sample_data/data/AD_NC/'\n",
        "\n",
        "transform_data = transforms.Compose([transforms.Resize((256, 256)),transforms.ToTensor()])\n",
        "\n",
        "train = datasets.ImageFolder(data_dir + 'train',transform_data)\n",
        "test= datasets.ImageFolder(data_dir + 'test',transform_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "ro9O_suckCus"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(train[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvXTGcxZnGXy",
        "outputId": "f253ba30-b4a1-40a7-f5f9-55a6fb13a360"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "iRY_n01npMui"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "    MIN_NUM_PATCHES = 4\n",
        "    def __init__(self,\n",
        "                 image_size=256,\n",
        "                 patch_size=16,\n",
        "                 embed_dim=768,\n",
        "                 input_channels=3):\n",
        "        super(PatchEmbedding, self).__init__()\n",
        "\n",
        "        self.image_size = image_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = 256\n",
        "\n",
        "        self.conv = nn.Conv2d(input_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "        # in = 3, out = 768 ,kernel = 16, stride = 16\n",
        "        self.cls_token = nn.Parameter(torch.randn(1,1, embed_dim))\n",
        "        self.positions = nn.Parameter(torch.randn((image_size // patch_size) **2 + 1, embed_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv(x)\n",
        "        b, c, h, w = x.shape #b,768,16,16\n",
        "        x = torch.reshape(x, (b, c, h * w))# batch,768,16*16\n",
        "        x = torch.transpose(x,  2, 1)#torch.Size([b, 256, 768])\n",
        "\n",
        "        cls_tokens = self.cls_token.repeat(b,1,1) #([b, 1, 768])\n",
        "        x = torch.cat([cls_tokens, x], dim=1)#([b, 257, 768])\n",
        "\n",
        "        positions = torch.randn((256// 16) **2 + 1, 768)\n",
        "        x += self.positions#([b, 257, 768])\n",
        "        # print(x.size())\n",
        "        return x"
      ],
      "metadata": {
        "id": "1wJJVmh2v7ey"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = PatchEmbedding()\n",
        "\n",
        "query = torch.randn([12,3, 256, 256])\n",
        "m = model(query)\n",
        "print ('Output size: ' + str(m.size()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBZHWVcWZbFS",
        "outputId": "cb48202a-8773-4dae-ad5c-a29b9e3b28ec"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([12, 257, 768])\n",
            "Output size: torch.Size([12, 257, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(PatchEmbedding(),(3,256,256))"
      ],
      "metadata": {
        "id": "TqBz93CkDx8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NODPSzzfk66N",
        "outputId": "b6de5e6b-1e6f-489f-d0e5-136cc1964070"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from einops import rearrange, reduce, repeat\n",
        "import math"
      ],
      "metadata": {
        "id": "3z-Z1s9qkvDp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![1665906834002.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "SeBs5dAmyGo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def scaled_dot_Attention(q, k, v, mask=None, dropout=None):\n",
        "    d_k = q.size(-1)\n",
        "    attn_logits = torch.matmul(q, k.transpose(-2, -1))/ math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        attn_logits = attn_logits.masked_fill(mask == 0, -1e9)\n",
        "    attention = F.softmax(attn_logits, dim=-1)\n",
        "    return torch.matmul(attention, v), attention"
      ],
      "metadata": {
        "id": "dOtQ0F8kanQc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = torch.randn(13,257, 768)\n",
        "q = rearrange( q , \"b n (h d) -> b h n d\", h=12)\n",
        "q.size()\n",
        "d_k = q.size(-1)\n",
        "d_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6X60HJday8y",
        "outputId": "bc7a4de3-4d3d-44a1-e821-72a0f588c685"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embed_dim=768,\n",
        "                 num_heads=12,\n",
        "                 dropout=0.0):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.K = nn.Linear(embed_dim,embed_dim)\n",
        "        self.Q = nn.Linear(embed_dim,embed_dim)\n",
        "        self.V = nn.Linear(embed_dim,embed_dim)\n",
        "        self.num_heads = 12\n",
        "        self.embed_dim=768\n",
        "        self.d_k = 64\n",
        "        self.lc = nn.Linear(embed_dim,embed_dim)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_length, _embed_dim = x.size()#([b, 257, 768])\n",
        "        key = self.K(x)\n",
        "        key = rearrange( key, \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        query = self.Q(x)\n",
        "        query = rearrange( query , \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        values = self.V(x)\n",
        "        values = rearrange( values, \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        \n",
        "        # (batch_size, head = 12, seq_length = 257, d = 64)\n",
        "        values, attention = scaled_dot_Attention(query, key, values, mask=mask)\n",
        "        # print(values.size())\n",
        "        values = rearrange(values, \"b h n d -> b n (h d)\")\n",
        "        # print(values.size())\n",
        "        values = self.lc(values)\n",
        "        # print(values.size())\n",
        "        return values"
      ],
      "metadata": {
        "id": "UAjWdGN-MWrO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn([1, 12, 257, 64])\n",
        "rearrange(a, \"b h n d -> b n (h d)\").size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uPHvAYZuaha",
        "outputId": "988f99c5-d3da-48a2-c493-e4e3e586f9d1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 257, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = MultiHeadAttention()\n",
        "\n",
        "query = torch.randn([1, 257, 768])\n",
        "key = query\n",
        "value = query\n",
        "\n",
        "print ('Input size: ' + str(query.size()))\n",
        "\n",
        "m = model(query)\n",
        "\n",
        "print ('Output size: ' + str(m.size()))"
      ],
      "metadata": {
        "id": "nkMN8f7hF6XD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8657dc35-95d1-491b-fd11-b6c7e291d43b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input size: torch.Size([1, 257, 768])\n",
            "torch.Size([1, 12, 257, 64])\n",
            "torch.Size([1, 257, 768])\n",
            "torch.Size([1, 257, 768])\n",
            "Output size: torch.Size([1, 257, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardBlock(nn.Module):\n",
        "    def __init__(self, emb_size=768, expansion = 4, drop_p = 0.0):\n",
        "        super(FeedForwardBlock, self).__init__()\n",
        "        self.layer_norm_1 = nn.LayerNorm(emb_size)\n",
        "        self.attn = nn.MultiheadAttention(emb_size,num_heads=12,dropout=0.0)\n",
        "        self.layer_norm_2 = nn.LayerNorm(emb_size)\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(emb_size, expansion * emb_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop_p),\n",
        "            nn.Linear(expansion * emb_size, emb_size),\n",
        "            nn.Dropout(drop_p)\n",
        "        )\n",
        "        # self.lc1= nn.Linear(emb_size, expansion * emb_size)\n",
        "        # self.act_1 = nn.GELU()\n",
        "        # self.drop = nn.Dropout(drop_p)\n",
        "        # self.lc2 = nn.Linear(expansion * emb_size, emb_size)\n",
        "      \n",
        "    def forward(self, x):\n",
        "        inp_x = self.layer_norm_1(x)\n",
        "        x = x + self.attn(inp_x, inp_x, inp_x)[0]\n",
        "        x = x + self.linear(self.layer_norm_2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "qNvCKwavFWKn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn([1, 257, 768])\n",
        "patches_embedded = FeedForwardBlock()(x).size()\n",
        "patches_embedded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KguKJyHXSoSQ",
        "outputId": "f22016d0-865f-466d-9e2d-e34539f21a5c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 257, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Sequential):\n",
        "    def __init__(self, depth: int = 6, **kwargs):\n",
        "        super().__init__(*[FeedForwardBlock(**kwargs) for _ in range(depth)])"
      ],
      "metadata": {
        "id": "wv4UWngeIYl-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerEncoder()\n",
        "\n",
        "query = torch.randn([12, 257, 768])\n",
        "m = model(query)\n",
        "print ('Output size: ' + str(m.size()))"
      ],
      "metadata": {
        "id": "SVr3QXVdZ88y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, emb_size: int = 768, n_classes: int = 2):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.nrom1 = nn.LayerNorm(emb_size)\n",
        "        self.lc1 = nn.Linear(emb_size, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = reduce(x,'b n e -> b e', reduction='mean')\n",
        "        x = self.nrom1(x)\n",
        "        x =  self.lc1(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "LEbuJBCGVqS2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = ClassificationHead()\n",
        "\n",
        "query = torch.randn([12, 257, 768])\n",
        "m = model(query)\n",
        "print ('Output size: ' + str(m.size()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrlgHbRvaKxZ",
        "outputId": "fd592edc-2f3a-481c-e108-b1e3b4acf379"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output size: torch.Size([12, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Sequential):\n",
        "    def __init__(self,     \n",
        "                in_channels: int = 3,\n",
        "                patch_size: int = 16,\n",
        "                emb_size: int = 768,\n",
        "                img_size: int = 256,\n",
        "                depth: int = 12,\n",
        "                n_classes: int = 2,\n",
        "                **kwargs):\n",
        "        super().__init__(\n",
        "            PatchEmbedding(),\n",
        "            TransformerEncoder(),\n",
        "            ClassificationHead()\n",
        "        )"
      ],
      "metadata": {
        "id": "t6RyF0Bqt2yc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(ViT(), (3, 256, 256), device='cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg9Pjpd1U0ba",
        "outputId": "2a7d169d-55e0-4b3b-838f-51f80348fbf0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 257, 768])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 768, 16, 16]         590,592\n",
            "    PatchEmbedding-2             [-1, 257, 768]               0\n",
            "            Linear-3            [-1, 257, 3072]       2,362,368\n",
            "              GELU-4            [-1, 257, 3072]               0\n",
            "           Dropout-5            [-1, 257, 3072]               0\n",
            "            Linear-6             [-1, 257, 768]       2,360,064\n",
            "  FeedForwardBlock-7             [-1, 257, 768]               0\n",
            "            Linear-8            [-1, 257, 3072]       2,362,368\n",
            "              GELU-9            [-1, 257, 3072]               0\n",
            "          Dropout-10            [-1, 257, 3072]               0\n",
            "           Linear-11             [-1, 257, 768]       2,360,064\n",
            " FeedForwardBlock-12             [-1, 257, 768]               0\n",
            "           Linear-13            [-1, 257, 3072]       2,362,368\n",
            "             GELU-14            [-1, 257, 3072]               0\n",
            "          Dropout-15            [-1, 257, 3072]               0\n",
            "           Linear-16             [-1, 257, 768]       2,360,064\n",
            " FeedForwardBlock-17             [-1, 257, 768]               0\n",
            "           Linear-18            [-1, 257, 3072]       2,362,368\n",
            "             GELU-19            [-1, 257, 3072]               0\n",
            "          Dropout-20            [-1, 257, 3072]               0\n",
            "           Linear-21             [-1, 257, 768]       2,360,064\n",
            " FeedForwardBlock-22             [-1, 257, 768]               0\n",
            "           Linear-23            [-1, 257, 3072]       2,362,368\n",
            "             GELU-24            [-1, 257, 3072]               0\n",
            "          Dropout-25            [-1, 257, 3072]               0\n",
            "           Linear-26             [-1, 257, 768]       2,360,064\n",
            " FeedForwardBlock-27             [-1, 257, 768]               0\n",
            "           Linear-28            [-1, 257, 3072]       2,362,368\n",
            "             GELU-29            [-1, 257, 3072]               0\n",
            "          Dropout-30            [-1, 257, 3072]               0\n",
            "           Linear-31             [-1, 257, 768]       2,360,064\n",
            " FeedForwardBlock-32             [-1, 257, 768]               0\n",
            "           Linear-33            [-1, 257, 3072]       2,362,368\n",
            "             GELU-34            [-1, 257, 3072]               0\n",
            "          Dropout-35            [-1, 257, 3072]               0\n",
            "           Linear-36             [-1, 257, 768]       2,360,064\n",
            " FeedForwardBlock-37             [-1, 257, 768]               0\n",
            "           Linear-38            [-1, 257, 3072]       2,362,368\n",
            "             GELU-39            [-1, 257, 3072]               0\n",
            "          Dropout-40            [-1, 257, 3072]               0\n",
            "           Linear-41             [-1, 257, 768]       2,360,064\n",
            " FeedForwardBlock-42             [-1, 257, 768]               0\n",
            "        LayerNorm-43                  [-1, 768]           1,536\n",
            "           Linear-44                    [-1, 2]           1,538\n",
            "ClassificationHead-45                    [-1, 2]               0\n",
            "================================================================\n",
            "Total params: 38,373,122\n",
            "Trainable params: 38,373,122\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 171.67\n",
            "Params size (MB): 146.38\n",
            "Estimated Total Size (MB): 318.80\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size=64, shuffle=True)\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "FcUqtvlhdrZv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_func(model, train_loader, lr = 0.0005, GPU_device = True, Epoch = 30):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=20,gamma=0.1)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for epoch in range(Epoch):\n",
        "        train_loss = 0.0\n",
        "        for batch_idx, data in enumerate(train_loader):\n",
        "            #print(batch_idx)\n",
        "            inputs, target = data\n",
        "            # print(target)\n",
        "\n",
        "            if use_cuda:\n",
        "                inputs = inputs.cuda()\n",
        "                target = target.cuda()\n",
        "                model.cuda()\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            output = model(inputs.float())\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            # print(predicted)\n",
        "\n",
        "            loss = criterion(predicted.float(),target.float())\n",
        "            loss.requires_grad_(True)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()*target.size(0)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        print(\"epoch:\",epoch+1, \"train_loss:\",train_loss)\n",
        "              "
      ],
      "metadata": {
        "id": "T7rHOj_pakS8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViT()\n",
        "lr = 0.1\n",
        "Epoch = 30\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=20,gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "for epoch in range(Epoch):\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        #print(batch_idx)\n",
        "        inputs, target = data\n",
        "        # print(target)\n",
        "\n",
        "        if use_cuda:\n",
        "            inputs = inputs.cuda()\n",
        "            target = target.cuda()\n",
        "            model.cuda()\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs.float())\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        # print(predicted)\n",
        "\n",
        "        loss = criterion(predicted.float(),target.float())\n",
        "        loss.requires_grad_(True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*target.size(0)\n",
        "\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "    print(\"epoch:\",epoch+1, \"train_loss:\",train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "i7zhMpH5l5u4",
        "outputId": "cb5b96ed-3989-4b34-9d05-2aa05b0e04ea"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 train_loss: 137.43887584785546\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-4d4689daa850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sIyzK5Mtvrq8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}