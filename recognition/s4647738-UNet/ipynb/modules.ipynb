{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Conv2DTranspose, Cropping2D, Concatenate, Dropout, Layer, Add, Input, LeakyReLU, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as k"
      ],
      "metadata": {
        "id": "GiRALCFcZofN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContextModule(Layer):\n",
        "  # Used during encoding, outputs context information to be passed to decoding\n",
        "  def __init__(self, filters, **kwargs):\n",
        "    super(ContextModule, self).__init__()\n",
        "    self.convA = Conv2D(filters = filters,\n",
        "                        kernel_size = (3,3),\n",
        "                        padding='same',\n",
        "                        activation = LeakyReLU(0.01))\n",
        "    self.dropout = Dropout(0.3)\n",
        "    self.convB = Conv2D(filters = filters,\n",
        "                        kernel_size = (3,3),\n",
        "                        padding = 'same',\n",
        "                        activation = LeakyReLU(0.01))\n",
        "  def call(self, inputs):\n",
        "    x = self.convA(inputs)\n",
        "    x = self.convB(x)\n",
        "    return self.dropout(x)\n",
        "  def get_config(self):\n",
        "    cfg = super().get_config()\n",
        "    return cfg  "
      ],
      "metadata": {
        "id": "yszKLeD7Ap3l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LocalizationModule(Layer):\n",
        "  # Used during decoding, helps localise structures of interest in image\n",
        "  def __init__(self, filters, **kwargs):\n",
        "    super(LocalizationModule, self).__init__()\n",
        "    self.convA = Conv2D(filters = filters,\n",
        "                        kernel_size = (3,3),\n",
        "                        padding='same',\n",
        "                        activation = LeakyReLU(0.01))\n",
        "    self.convB = Conv2D(filters = filters,\n",
        "                        kernel_size = (1,1),\n",
        "                        padding='same',\n",
        "                        activation = LeakyReLU(0.01))\n",
        "  def call(self, inputs):\n",
        "    x = self.convA(inputs)\n",
        "    return self.convB(x)\n",
        "  def get_config(self):\n",
        "    cfg = super().get_config()\n",
        "    return cfg  "
      ],
      "metadata": {
        "id": "6ngQqETTAtVc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationModule(Layer):\n",
        "  # Helps with passing information up decoding section of UNet\n",
        "  def __init__(self, filters, upscale = True, **kwargs):\n",
        "    super(SegmentationModule, self).__init__()\n",
        "    self.conv = Conv2D(filters = filters, \n",
        "                       kernel_size = (3, 3), \n",
        "                       padding='same',\n",
        "                       activation = LeakyReLU(0.01))\n",
        "    self.up = UpSampling2D(size = (2, 2))\n",
        "    self.upscale = upscale\n",
        "  def call(self, inputs):\n",
        "    x = self.conv(inputs)\n",
        "    if self.upscale:\n",
        "      return self.up(x)\n",
        "    else:\n",
        "      return x\n",
        "  def get_config(self):\n",
        "    cfg = super().get_config()\n",
        "    return cfg  "
      ],
      "metadata": {
        "id": "ObI0tUrtAtao"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def improved_unet():\n",
        "  ### ENCODER ###\n",
        "  inputs = Input(shape=(256, 256, 1))\n",
        "  # layer 1\n",
        "  conv1 = Conv2D(filters = 16, kernel_size = (3,3), padding='same', activation = LeakyReLU(0.01))(inputs)\n",
        "  context1 = ContextModule(16)(conv1) \n",
        "  add1 = Add()([conv1, context1])\n",
        "\n",
        "  # layer 2\n",
        "  conv2 = Conv2D(filters = 32, kernel_size = (3,3), padding='same', strides = 2, activation = LeakyReLU(0.01))(add1)\n",
        "  context2 = ContextModule(32)(conv2)\n",
        "  add2 = Add()([conv2, context2])\n",
        "\n",
        "  # layer 3\n",
        "  conv3 = Conv2D(filters = 64, kernel_size = (3,3), padding='same', strides = 2, activation = LeakyReLU(0.01))(add2)\n",
        "  context3 = ContextModule(64)(conv3)\n",
        "  add3 = Add()([conv3, context3])\n",
        "\n",
        "  # layer 4\n",
        "  conv4 = Conv2D(filters = 128, kernel_size = (3,3), padding='same', strides = 2, activation = LeakyReLU(0.01))(add3)\n",
        "  context4 = ContextModule(128)(conv4)\n",
        "  add4 = Add()([conv4, context4])\n",
        "\n",
        "  # layer 5\n",
        "  conv5 = Conv2D(filters = 256, kernel_size = (3,3), padding='same', strides = 2, activation = LeakyReLU(0.01))(add4)\n",
        "  context5 = ContextModule(256)(conv5)\n",
        "  add5 = Add()([conv5, context5])\n",
        "  ### DECODER ###\n",
        "  up1 = UpSampling2D()(add5)\n",
        "\n",
        "  # layer 4\n",
        "  concat1 = Concatenate()([up1, add4])\n",
        "  localization1 = LocalizationModule(128)(concat1)\n",
        "  up2 = UpSampling2D()(localization1)\n",
        "\n",
        "  # layer 3\n",
        "  concat2 = Concatenate()([up2, add3])\n",
        "  localization2 = LocalizationModule(64)(concat2)\n",
        "  up3 = UpSampling2D()(localization2)\n",
        "  seg1 = SegmentationModule(2)(localization2)\n",
        "\n",
        "  # layer 2\n",
        "  concat3 = Concatenate()([up3, add2])\n",
        "  localization3 = LocalizationModule(32)(concat3)\n",
        "  up4 = UpSampling2D()(localization3)\n",
        "  seg2 = SegmentationModule(2)(localization3)\n",
        "  seg1up = UpSampling2D((2,2))(seg1) # Upsample seg1 to match seg2 shape\n",
        "  add6 = Add()([seg1up, seg2])\n",
        "\n",
        "  # layer 1\n",
        "  concat4 = Concatenate()([up4, add1])\n",
        "  conv2 = Conv2D(filters = 32, kernel_size = (3,3), padding='same', activation = LeakyReLU(0.01))(concat4)\n",
        "  seg3 = SegmentationModule(2, upscale=False)(conv2)\n",
        "  add7 = Add()([seg3, add6])\n",
        "  outputs = Conv2D(filters = 2, kernel_size = (3, 3), padding='same', activation='softmax')(add7)\n",
        "  model = Model(inputs, outputs)\n",
        "  return model"
      ],
      "metadata": {
        "id": "YoYo1n9KDuzA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_similarity(y, x):\n",
        "  \"\"\"\n",
        "  Calculates dice similarity coefficient of the model's output\n",
        "  \"\"\"\n",
        "  xim = tf.where(x[:, :, :, 1] >= x[:, :, :, 0], [1.0], [0.0])\n",
        "  xc = k.flatten(xim)\n",
        "  yc = k.flatten(y)\n",
        "  intersect = k.sum(xc * yc)\n",
        "  union = k.sum(xc) + k.sum(yc)\n",
        "  return 2 * intersect / union"
      ],
      "metadata": {
        "id": "vsMZ1-X1Aynv"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}